<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <!-- TODO: Replace with your paper title and author names -->
  <meta name="title" content="Improving Semantic Uncertainty Quantification in Language Models via Token-Level Temperature Scaling - Tom A. Lamb, Desi Ivanova, Philip H.S. Torr, and Tim G.J. Rudner">
  <!-- TODO: Write a compelling 150-160 character description of your research -->
  <meta name="description" content="This paper introduces new semantic confidence measures and shows that simple token-level temperature optimisation improves calibration, discrimination, and entropy-based uncertainty in LLMs, outperforming heuristic and complex calibration methods.">
  <!-- TODO: Add 5-10 relevant keywords for your research area -->
  <meta name="keywords" content="Semantic Calibration, LLMs, NLP, Uncertainty Quantificaiton, Semantic Entropy">
  <!-- TODO: List all authors -->
  <meta name="author" content="Tom A. Lamb, Desi Ivanova, Philip H.S. Torr, Tim G.J. Rudner">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <!-- TODO: Replace with your institution or lab name -->
  <meta property="og:site_name" content="INSTITUTION_OR_LAB_NAME">
  <!-- TODO: Same as paper title above -->
  <meta property="og:title" content="Improving Semantic Uncertainty Quantification in Language Models via Token-Level Temperature Scaling">
  <!-- TODO: Same as description above -->
  <meta property="og:description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <!-- TODO: Replace with your actual website URL -->
  <meta property="og:url" content="https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE">
  <!-- TODO: Create a 1200x630px preview image and update path -->
  <meta property="og:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="Improving Semantic Uncertainty Quantification in Language Models via Token-Level Temperature Scaling - Research Preview">
  <meta property="article:published_time" content="2024-01-01T00:00:00.000Z">
  <meta property="article:author" content="FIRST_AUTHOR_NAME">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="KEYWORD1">
  <meta property="article:tag" content="KEYWORD2">

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <!-- TODO: Replace with your lab/institution Twitter handle -->
  <meta name="twitter:site" content="@YOUR_TWITTER_HANDLE">
  <!-- TODO: Replace with first author's Twitter handle -->
  <meta name="twitter:creator" content="@AUTHOR_TWITTER_HANDLE">
  <!-- TODO: Same as paper title above -->
  <meta name="twitter:title" content="Improving Semantic Uncertainty Quantification in Language Models via Token-Level Temperature Scaling">
  <!-- TODO: Same as description above -->
  <meta name="twitter:description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <!-- TODO: Same as social preview image above -->
  <meta name="twitter:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta name="twitter:image:alt" content="Improving Semantic Uncertainty Quantification in Language Models via Token-Level Temperature Scaling">

  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="Improving Semantic Uncertainty Quantification in Language Models via Token-Level Temperature Scaling">
  <meta name="citation_author" content="FIRST_AUTHOR_LAST, FIRST_AUTHOR_FIRST">
  <meta name="citation_author" content="SECOND_AUTHOR_LAST, SECOND_AUTHOR_FIRST">
  <meta name="citation_publication_date" content="2024">
  <meta name="citation_conference_title" content="CONFERENCE_NAME">
  <meta name="citation_pdf_url" content="https://YOUR_DOMAIN.com/static/pdfs/paper.pdf">
  
  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <!-- TODO: Replace with your paper title and authors -->
  <title>Improving Semantic Uncertainty Quantification in Language Models via Token-Level Temperature Scaling - Tom A. Lamb, Desi Ivanova, Philip H.S. Torr, and Tim G.J. Rudner</title>
  
  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/x-icon" href="static/images/Oxford-avatar.png">
  <link rel="apple-touch-icon" href="static/images/Oxford-avatar.png">
  
  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "Improving Semantic Uncertainty Quantification in Language Models via Token-Level Temperature Scaling",
    "description": "BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS",
    "author": [
      {
        "@type": "Person",
        "name": "FIRST_AUTHOR_NAME",
        "affiliation": {
          "@type": "Organization",
          "name": "INSTITUTION_NAME"
        }
      },
      {
        "@type": "Person",
        "name": "SECOND_AUTHOR_NAME",
        "affiliation": {
          "@type": "Organization",
          "name": "INSTITUTION_NAME"
        }
      }
    ],
    "datePublished": "2024-01-01",
    "publisher": {
      "@type": "Organization",
      "name": "CONFERENCE_OR_JOURNAL_NAME"
    },
    "url": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE",
    "image": "https://YOUR_DOMAIN.com/static/images/social_preview.png",
    "keywords": ["KEYWORD1", "KEYWORD2", "KEYWORD3", "machine learning", "computer vision"],
    "abstract": "FULL_ABSTRACT_TEXT_HERE",
    "citation": "BIBTEX_CITATION_HERE",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE"
    },
    "about": [
      {
        "@type": "Thing",
        "name": "RESEARCH_AREA_1"
      },
      {
        "@type": "Thing", 
        "name": "RESEARCH_AREA_2"
      }
    ]
  }
  </script>
  
  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "INSTITUTION_OR_LAB_NAME",
    "url": "https://YOUR_INSTITUTION_WEBSITE.com",
    "logo": "https://YOUR_DOMAIN.com/static/images/Oxford-avatar.png",
    "sameAs": [
      "https://twitter.com/YOUR_TWITTER_HANDLE",
      "https://github.com/YOUR_GITHUB_USERNAME"
    ]
  }
  </script>
</head>
<body>


  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>

  <main id="main-content">
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <!-- TODO: Replace with your paper title -->
            <h1 class="title is-1 publication-title">Improving Semantic Uncertainty Quantification in Language Models via Token-Level Temperature Scaling</h1>
            <div class="is-size-5 publication-authors">
              <!-- TODO: Replace with your paper authors and their personal links -->
              <span class="author-block">
                <a href="https://tomalamb.github.io/" target="_blank">Tom A. Lamb</a><sup>1</sup></span>,
                <span class="author-block">
                  <a href="https://desirivanova.com/" target="_blank">Desi Ivanova</a><sup>1</sup></span>,
                  <span class="author-block">
                    <a href="https://www.robots.ox.ac.uk/~phst/" target="_blank">Philip H.S. Torr</a><sup>1</sup></span>,
                      <span class="author-block">
                         <a href="https://timrudner.com/" target="_blank">Tim G. J. Rudner</a><sup>2</sup>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">
                      <sup>1</sup>University of Oxford&nbsp;&nbsp;&nbsp;
                      <sup>2</sup>University of Toronto
                    </span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- TODO: Update with your arXiv paper ID -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                  <!-- TODO: Replace with your GitHub repository URL -->
                  <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- TODO: Update with your arXiv paper ID -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Motivation section -->
<section class="section hero is-white">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Motivation</h2>
        <figure class="image">
          <!-- If you have converted the PDF to an image, use that -->
          <img src="static/images/motivation_single.png" alt="Motivation figure">
        </figure>
        <!-- Optional caption -->
        <p>
          <strong>Temperature Scaling Improves Semantic Uncertainty Quantification.</strong> We compare the same base model with different temperature parameters, each generating ten responses for the same input, and cluster responses into semantic groups. We compute the semantic confidence measure introdcued by <a href="#ref-kuhn2023semantic">Kuhn et&nbsp;al.&nbsp;(2023)</a>. Panel <strong>(a)</strong> uses the recommended temperature of 0.5. Panel <strong>(b)</strong> uses a temperature optimized on a calibration set. Optimised temperature scaling offers a simple way to improve both semantic calibration and discrimination.
        </p>
      </div>
    </div>
  </div>
</section>
<!-- End motivation section -->

<section class="section">
  <div class="container is-max-desktop">
    <div class="box has-background-light">
      <h2 class="title is-4 has-text-centered">Key research question</h2>
      <div class="content">
        <p class="is-size-5 has-text-centered">
          How does optimising a single token-level temperature parameter affect the semantic calibration and discrimination of semantic confidence measures, and the discriminability of quantities such as semantic entropy derived from these confidence measures?
        </p>
      </div>
    </div>
  </div>
</section>

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <!-- TODO: Replace with your paper abstract -->
          <p>
            Calibration is central to reliable semantic uncertainty quantification in language models, yet prior work has largely focused on the discriminative use of semantic uncertainty, neglecting calibration. In this paper, we address this gap in the literature and study both semantic calibration and discrimination across a broad set of semantic confidence measures. We conduct a careful empirical evaluation and find that optimising a single, token-level temperature parameter is a simple and effective method for improving semantic uncertainty quantification. Across semantic confidence measures, models, and QA datasets, token-level temperature optimisation consistently improves semantic calibration, discrimination, and semantic entropy. Notably, uncertainty-focused temperature optimisation outperforms both widely-used fixed-temperature baselines and more sophisticated calibration methods for semantic uncertainty quantification.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Semantic Confidence Measures</h2>
          <figure class="image">
          <!-- If you have converted the PDF to an image, use that -->
          <img src="static/images/methodology.png" alt="Motivation figure">
        </figure>
        <div class="content has-text-justified">
          <!-- TODO: Replace with your paper abstract -->
          <p class="is-size-6 has-text-grey mt-3"><em>Figure:</em> Figure showing how existing <a href="#ref-farquhar2024detecting">E-SC&nbsp;(Farquhar&nbsp;et&nbsp;al., 2024)</a> and <a href="#ref-kuhn2023semantic">L-SC&nbsp;(Kuhn&nbsp;et&nbsp;al., 2023)</a>, as well as a broad set of novel baseline semantic measures (ML-SC, B-SC, T-SC, IC-SC, and G-SC), are computed. For an input \( \mathbf{x} \), we sample multiple responses from the model \( p(\cdot \mid \mathbf{x}) \), and use an NLI model to assess bidirectional entailment, determining whether responses \( \mathbf{y}^{i} \) and \( \mathbf{y}^{j} \) are semantically equivalent (\( \mathbf{y}^{i} \sim \mathbf{y}^{j} \mid \mathbf{x} \)). Here, \( s(C \mid \mathbf{x}) \) denotes the sum, \( \bar{s}(C \mid \mathbf{x}) \) the average, \( \mathcal{H}(p_{C_i}) \) the entropy, and \( \mathcal{E}(C_i \mid \mathbf{x}) \) the entropy of the length-normalised log-likelihoods of generations within cluster \( C \). See <a href="#sec-confidence-measures">Section&nbsp;Confidence&nbsp;Measures</a> for further details.</p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Methodology Section -->
<section class="section hero is-white">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Methodology</h2>
        <div class="content has-text-justified">
          <p>
            We evaluate the calibration and discrimination of semantic confidence measures across multiple question-answering datasets, including TriviaQA, Natural Questions, and SQuAD, using popular instruction-tuned language models. To investigate the affect of optimisng temperature paramters (Temperature Scaling (TS)) on semantic uncertainty quantification, we and compare against several baseline post-hoc, token-level recalibration techniques: an <strong>Adaptive Temperature Scaling (ATS)</strong> head that predicts token-specific temperatures, <strong>Platt Scaling</strong> with a diagonal affine logit transform, and fixed-temperature baselines of τ = 1.0 (Base) and τ = 0.5 (SE). We compare how each method influences semantic calibration, discrimination, and uncertainty across semantic confidence measures.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Results Section -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Results</h2>

        <div class="content has-text-justified">
          <p>
            We report results across models (7-8B Llama, Qwen and Mistral models) and question-answering datasets (closed book: TriviaQA and Natural Questions; open book: SQuAD), focusing on how different token-level
            recalibration techniques impact semantic calibration and discrimination.
          </p>
        </div>

        <!-- Subsection 1 -->
        <h3 class="title is-4 has-text-left mt-5">Temperature Scaling Improves Semantic Calibration and Discrimination</h3>
        <div class="content has-text-justified">
          <p>
            Optimised <strong>Temperature Scaling (TS)</strong> consistently improves semantic uncertainty
            quantification, outperforming both fixed-temperature heuristics (Base and SE) used in prior work,  and more complex calibration
            methods such as <strong>Adaptive Temperature Scaling (ATS)</strong> and <strong>Platt Scaling</strong>.
            Improvements hold across all question-answering datasets, demonstrating that TS provides a simple,
            robust, and effective means of enhancing both semantic calibration and discrimination of semantic
            confidence measures.
          </p>
        </div>

        <!-- First results figure -->
        <div class="box">
          <figure class="image">
            <img src="static/images/calibration_scatter_best.png" alt="Results figure 1: Semantic calibration and discrimination metrics">
          </figure>
          <p class="is-size-6 has-text-grey mt-3">
            <em>Figure:</em> <strong>Uncertainty Metrics of SC Measures Across Methods.</strong> Mean and standard error of \( \widehat{\mathrm{ACE}} \) (\( \downarrow \)) and AUROC (\( \uparrow \)) scores for SC measures across baseline, calibration methods, and datasets. <em>Closer to the top-left of plots indicates better discrimination and calibration, and hence better overall semantic uncertainty quantification.</em>
          </p>
        </div>

        <!-- Subsection 2 -->
        <h3 class="title is-4 has-text-left mt-6">Temperature Scaling Improves Discriminability of the Semantic Entropy Derived from Semantic Confidence Measures</h3>
        <div class="content has-text-justified">
          <p>
            Building on the calibration and discrimination results above, we next evaluate how
            token-level temperature optimisation affects downstream <strong>semantic entropy (SE)</strong>.
            We compare a principled formulation, <strong>SE<sub>conf</sub></strong>, where the final answer
            is drawn from the most confident semantic cluster, against the heuristic baseline
            <strong>SE<sub>vanilla</sub></strong> that determines correctness via greedy decoding while
            sampling from a temperature-smoothed distribution. Across datasets, optimised temperature
            scaling (<strong>TS</strong>) consistently improves the discriminative power of entropy under
            both definitions, surpassing fixed-temperature heuristics (Base and SE with τ ∈ {0.5, 1.0}) and demonstrating
            that aligning prediction and uncertainty distributions yields more reliable semantic
            uncertainty estimates.
          </p>
        </div>

        <!-- Second results figure -->
        <div class="box">
          <figure class="image">
            <img src="static/images/se_comparison.png" alt="Results figure 2: Uncertainty measures and semantic entropy comparison">
          </figure>
          <p class="is-size-6 has-text-grey mt-3">
            <em>Figure:</em> <strong>Discrimination Comparison of Entropy for Qwen.</strong> Mean and standard error of AUROC (\( \uparrow \)) values. (a) reports \( \mathrm{SE}_{\mathrm{conf}} \), where correctness is determined by the most confident semantic cluster under a given SC measure. (b) reports \( \mathrm{SE}_{\mathrm{vanilla}} \) from <a href="#ref-kuhn2023semantic">Kuhn&nbsp;et&nbsp;al.&nbsp;(2023)</a>, where correctness is determined via greedy decoding. Bold entries denote the best result within each SC measure per dataset, and <u>underlined</u> entries indicate the best overall per dataset.
          </p>
        </div>

      </div>
    </div>
  </div>
</section>

<!-- Key Takeaways -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="box has-background-light">
      <h2 class="title is-3 has-text-centered">Key Takeaways</h2>
      <div class="content">
        <ul>
          <li><strong>Temperature scaling (TS)</strong> is a simple yet highly effective method for improving semantic uncertainty quantification in language models.</li>
          <li>Optimising a single scalar temperature parameter substantially enhances both <strong>semantic calibration</strong> and <strong>discrimination</strong> across QA datasets.</li>
          <li>TS consistently outperforms more complex methods such as <strong>Adaptive Temperature Scaling (ATS)</strong> and <strong>Platt Scaling</strong>.</li>
          <li>Fixed-temperature baselines (τ = 1.0 and τ = 0.5) used in prior work are suboptimal for semantic calibration.</li>
          <li>Better calibrated semantic confidence measures lead to more reliable downstream uncertainty metrics such as semantic entropy.</li>
          <li>Overall, token-level temperature optimisation provides a <strong>simple, robust, and computationally efficient</strong> approach for improving the reliability of language models.</li>
        </ul>
      </div>
    </div>
  </div>
</section>





<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <div class="bibtex-header">
        <h2 class="title">BibTeX</h2>
        <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
          <i class="fas fa-copy"></i>
          <span class="copy-text">Copy</span>
        </button>
      </div>
      <pre id="bibtex-code"><code>@article{lamb2025,
  title={Improving Semantic Uncertainty Quantification in Language Models via Token-Level Temperature Scaling},
  author={Lamb, T.A. and Ivanova, Desi and Torr, Philip H.S. and Rudner, Tim G.J.},
  journal={arXiv preprint},
  year={2025},
  archivePrefix={arXiv},
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> 
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->
     <script>
  window.MathJax = {
    tex: { inlineMath: [['\\(', '\\)'], ['$', '$']] },
    svg: { fontCache: 'global' }
  };
</script>
<script id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>

  </body>
  </html>
