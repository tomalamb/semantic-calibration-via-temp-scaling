<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <!-- TODO: Replace with your paper title and author names -->
  <meta name="title" content="Improving Semantic Uncertainty Quantification in Language Models via Token-Level Temperature Scaling - Tom A. Lamb, Desi Ivanova, Philip H.S. Torr, and Tim G.J. Rudner">
  <!-- TODO: Write a compelling 150-160 character description of your research -->
  <meta name="description" content="This paper introduces new semantic confidence measures and shows that simple token-level temperature optimisation improves calibration, discrimination, and entropy-based uncertainty in LLMs, outperforming heuristic and complex calibration methods.">
  <!-- TODO: Add 5-10 relevant keywords for your research area -->
  <meta name="keywords" content="Semantic Calibration, LLMs, NLP, Uncertainty Quantificaiton, Semantic Entropy">
  <!-- TODO: List all authors -->
  <meta name="author" content="Tom A. Lamb, Desi Ivanova, Philip H.S. Torr, Tim G.J. Rudner">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <!-- TODO: Replace with your institution or lab name -->
  <meta property="og:site_name" content="INSTITUTION_OR_LAB_NAME">
  <!-- TODO: Same as paper title above -->
  <meta property="og:title" content="Improving Semantic Uncertainty Quantification in Language Models via Token-Level Temperature Scaling">
  <!-- TODO: Same as description above -->
  <meta property="og:description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <!-- TODO: Replace with your actual website URL -->
  <meta property="og:url" content="https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE">
  <!-- TODO: Create a 1200x630px preview image and update path -->
  <meta property="og:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="Improving Semantic Uncertainty Quantification in Language Models via Token-Level Temperature Scaling - Research Preview">
  <meta property="article:published_time" content="2024-01-01T00:00:00.000Z">
  <meta property="article:author" content="FIRST_AUTHOR_NAME">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="KEYWORD1">
  <meta property="article:tag" content="KEYWORD2">

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <!-- TODO: Replace with your lab/institution Twitter handle -->
  <meta name="twitter:site" content="@YOUR_TWITTER_HANDLE">
  <!-- TODO: Replace with first author's Twitter handle -->
  <meta name="twitter:creator" content="@AUTHOR_TWITTER_HANDLE">
  <!-- TODO: Same as paper title above -->
  <meta name="twitter:title" content="Improving Semantic Uncertainty Quantification in Language Models via Token-Level Temperature Scaling">
  <!-- TODO: Same as description above -->
  <meta name="twitter:description" content="BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS">
  <!-- TODO: Same as social preview image above -->
  <meta name="twitter:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta name="twitter:image:alt" content="Improving Semantic Uncertainty Quantification in Language Models via Token-Level Temperature Scaling - Research Preview">

  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="Improving Semantic Uncertainty Quantification in Language Models via Token-Level Temperature Scaling">
  <meta name="citation_author" content="FIRST_AUTHOR_LAST, FIRST_AUTHOR_FIRST">
  <meta name="citation_author" content="SECOND_AUTHOR_LAST, SECOND_AUTHOR_FIRST">
  <meta name="citation_publication_date" content="2024">
  <meta name="citation_conference_title" content="CONFERENCE_NAME">
  <meta name="citation_pdf_url" content="https://YOUR_DOMAIN.com/static/pdfs/paper.pdf">
  
  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <!-- TODO: Replace with your paper title and authors -->
  <title>Improving Semantic Uncertainty Quantification in Language Models via Token-Level Temperature Scaling - Tom A. Lamb, Desi Ivanova, Philip H.S. Torr, and Tim G.J. Rudner</title>
  
  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link rel="apple-touch-icon" href="static/images/favicon.ico">
  
  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "PAPER_TITLE",
    "description": "BRIEF_DESCRIPTION_OF_YOUR_RESEARCH_CONTRIBUTION_AND_FINDINGS",
    "author": [
      {
        "@type": "Person",
        "name": "FIRST_AUTHOR_NAME",
        "affiliation": {
          "@type": "Organization",
          "name": "INSTITUTION_NAME"
        }
      },
      {
        "@type": "Person",
        "name": "SECOND_AUTHOR_NAME",
        "affiliation": {
          "@type": "Organization",
          "name": "INSTITUTION_NAME"
        }
      }
    ],
    "datePublished": "2024-01-01",
    "publisher": {
      "@type": "Organization",
      "name": "CONFERENCE_OR_JOURNAL_NAME"
    },
    "url": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE",
    "image": "https://YOUR_DOMAIN.com/static/images/social_preview.png",
    "keywords": ["KEYWORD1", "KEYWORD2", "KEYWORD3", "machine learning", "computer vision"],
    "abstract": "FULL_ABSTRACT_TEXT_HERE",
    "citation": "BIBTEX_CITATION_HERE",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://YOUR_DOMAIN.com/YOUR_PROJECT_PAGE"
    },
    "about": [
      {
        "@type": "Thing",
        "name": "RESEARCH_AREA_1"
      },
      {
        "@type": "Thing", 
        "name": "RESEARCH_AREA_2"
      }
    ]
  }
  </script>
  
  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "INSTITUTION_OR_LAB_NAME",
    "url": "https://YOUR_INSTITUTION_WEBSITE.com",
    "logo": "https://YOUR_DOMAIN.com/static/images/favicon.ico",
    "sameAs": [
      "https://twitter.com/YOUR_TWITTER_HANDLE",
      "https://github.com/YOUR_GITHUB_USERNAME"
    ]
  }
  </script>
</head>
<body>


  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>

  <main id="main-content">
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <!-- TODO: Replace with your paper title -->
            <h1 class="title is-1 publication-title">Improving Semantic Uncertainty Quantification in Language Models via Token-Level Temperature Scaling</h1>
            <div class="is-size-5 publication-authors">
              <!-- TODO: Replace with your paper authors and their personal links -->
              <span class="author-block">
                <a href="https://tomalamb.github.io/" target="_blank">Tom A. Lamb</a><sup>1</sup></span>,
                <span class="author-block">
                  <a href="https://desirivanova.com/" target="_blank">Desi Ivanova</a><sup>1</sup></span>,
                  <span class="author-block">
                    <a href="https://www.robots.ox.ac.uk/~phst/" target="_blank">Philip H.S. Torr</a><sup>1</sup></span>,
                      <span class="author-block">
                         <a href="https://timrudner.com/" target="_blank">Tim G. J. Rudner</a><sup>2</sup>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">
                      <sup>1</sup>University of Oxford&nbsp;&nbsp;&nbsp;
                      <sup>2</sup>University of Toronto
                    </span>
                    <span class="eql-cntrb">
                      <small><br><sup>*</sup>Indicates Equal Contribution</small>
                    </span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- TODO: Update with your arXiv paper ID -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                  <!-- TODO: Replace with your GitHub repository URL -->
                  <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- TODO: Update with your arXiv paper ID -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Motivation section -->
<section class="section hero is-white">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Motivation</h2>
        <figure class="image">
          <!-- If you have converted the PDF to an image, use that -->
          <img src="static/images/motivation_single.png" alt="Motivation figure">
        </figure>
        <!-- Optional caption -->
        <p>
          <strong>Temperature Scaling Improves Semantic Uncertainty Quantification.</strong> We compare two models with different temperatures, each generating ten responses for the same input, and cluster responses into semantic groups. We compute the semantic confidence measure introdcued by <a href="#ref-kuhn2023semantic">Kuhn et&nbsp;al.&nbsp;(2023)</a>. Panel <strong>(a)</strong> uses the recommended temperature of 0.5. Panel <strong>(b)</strong> uses a temperature optimized on a calibration set. Temperature scaling offers a simple way to improve both semantic calibration and discrimination.
        </p>
      </div>
    </div>
  </div>
</section>
<!-- End motivation section -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <!-- TODO: Replace with your paper abstract -->
          <p>
            Calibration is central to reliable semantic uncertainty quantification in language models, yet prior work has largely focused on the discriminative use of semantic uncertainty, neglecting calibration. In this paper, we address this gap in the literature and study both semantic calibration and discrimination across a broad set of semantic confidence measures. We conduct a careful empirical evaluation and find that optimising a single, token-level temperature parameter is a simple and effective method for improving semantic uncertainty quantification. Across semantic confidence measures, models, and QA datasets, token-level temperature optimisation consistently improves semantic calibration, discrimination, and semantic entropy. Notably, uncertainty-focused temperature optimisation outperforms both widely-used fixed-temperature baselines and more sophisticated calibration methods for semantic uncertainty quantification.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Semantic Confidence Measures</h2>
          <figure class="image">
          <!-- If you have converted the PDF to an image, use that -->
          <img src="static/images/methodology.png" alt="Motivation figure">
        </figure>
        <div class="content has-text-justified">
          <!-- TODO: Replace with your paper abstract -->
          <p class="is-size-6 has-text-grey mt-3"><em>Figure:</em> Figure showing how existing <a href="#ref-farquhar2024detecting">E-SC&nbsp;(Farquhar&nbsp;et&nbsp;al., 2024)</a> and <a href="#ref-kuhn2023semantic">L-SC&nbsp;(Kuhn&nbsp;et&nbsp;al., 2023)</a>, as well as a broad set of novel baseline semantic measures (ML-SC, B-SC, T-SC, IC-SC, and G-SC), are computed. For an input \( \mathbf{x} \), we sample multiple responses from the model \( p(\cdot \mid \mathbf{x}) \), and use an NLI model to assess bidirectional entailment, determining whether responses \( \mathbf{y}^{i} \) and \( \mathbf{y}^{j} \) are semantically equivalent (\( \mathbf{y}^{i} \sim \mathbf{y}^{j} \mid \mathbf{x} \)). Here, \( s(C \mid \mathbf{x}) \) denotes the sum, \( \bar{s}(C \mid \mathbf{x}) \) the average, \( \mathcal{H}(p_{C_i}) \) the entropy, and \( \mathcal{E}(C_i \mid \mathbf{x}) \) the entropy of the length-normalised log-likelihoods of generations within cluster \( C \). See <a href="#sec-confidence-measures">Section&nbsp;Confidence&nbsp;Measures</a> for further details.</p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Methodology Section -->
<section class="section hero is-white">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Methodology</h2>
        <div class="content has-text-justified">
          <p>
            We evaluate our approach across multiple question-answering datasets, including TriviaQA, Natural Questions, and SQuAD, using popular instruction-tuned language models. To study how token-level calibration affects semantic calibration, we test several post-hoc recalibration techniques: a single scalar <strong>Temperature Scaling (TS)</strong>, an <strong>Adaptive Temperature Scaling (ATS)</strong> head that predicts token-specific temperatures, <strong>Platt Scaling</strong> with a diagonal affine logit transform, and fixed-temperature baselines of τ = 1.0 (Base) and τ = 0.5 (SE). We compare how each method influences semantic calibration, discrimination, and uncertainty across semantic confidence measures.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Results Section -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Results</h2>

        <div class="content has-text-justified">
          <p>
            We report results across models and datasets, focusing on how different token-level
            recalibration techniques impact semantic calibration and discrimination. Optimised
            <strong>Temperature Scaling (TS)</strong> consistently improves semantic uncertainty
            quantification, outperforming both fixed-temperature heuristics and more complex
            calibration methods such as <strong>ATS</strong> and <strong>Platt Scaling</strong>.
            Improvements hold across question-answering datasets, demonstrating the robustness of
            temperature-based semantic recalibration.
          </p>
        </div>

        <!-- First results figure -->
        <div class="box">
          <figure class="image">
            <img src="static/images/calibration_scatter_best.png" alt="Results figure 1: Semantic calibration and discrimination metrics">
          </figure>
          <p class="is-size-6 has-text-grey mt-3">
            <p class="is-size-6 has-text-grey mt-3"><em>Figure:</em> <strong>Uncertainty Metrics of SC Measures Across Methods.</strong> Mean and standard error of \( \widehat{\mathrm{ACE}} \) (\( \downarrow \)) and AUROC (\( \uparrow \)) scores for SC measures across baseline, calibration methods, and datasets. <em>Closer to the top-left of plots indicates better discrimination and calibration, and hence better overall semantic uncertainty quantification.</em></p>
          </p>
        </div>

        <!-- Second results figure -->
        <div class="box">
          <figure class="image">
            <img src="static/images/se_comparison.png" alt="Results figure 2: Uncertainty measures and semantic entropy comparison">
          </figure>
          <p class="is-size-6 has-text-grey mt-3">
            <p class="is-size-6 has-text-grey mt-3"><em>Figure:</em> <strong>Discrimination Comparison of Entropy for Qwen.</strong> Mean and standard error of AUROC (\( \uparrow \)) values. (a) reports \( \mathrm{SE}_{\mathrm{conf}} \), where correctness is determined by the most confident semantic cluster under a given SC measure. (b) reports \( \mathrm{SE}_{\mathrm{vanilla}} \) from <a href="#ref-kuhn2023semantic">Kuhn&nbsp;et&nbsp;al.&nbsp;(2023)</a>, where correctness is determined via greedy decoding. Bold entries denote the best result within each SC measure per dataset, and <u>underlined</u> entries indicate the best overall per dataset.</p>
          </p>
        </div>

      </div>
    </div>
  </div>
</section>

<!-- Key Takeaways -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="box has-background-light">
      <h2 class="title is-4 has-text-centered">Key Takeaways</h2>
      <div class="content">
        <ul>
          <li><strong>Temperature scaling (TS)</strong> is a simple yet highly effective method for improving semantic uncertainty quantification in language models.</li>
          <li>Optimising a single scalar temperature parameter substantially enhances both <strong>semantic calibration</strong> and <strong>discrimination</strong> across QA datasets.</li>
          <li>TS consistently outperforms more complex methods such as <strong>Adaptive Temperature Scaling (ATS)</strong> and <strong>Platt Scaling</strong>.</li>
          <li>Fixed-temperature baselines (τ = 1.0 and τ = 0.5) used in prior work are suboptimal for semantic calibration.</li>
          <li>Better calibrated semantic confidence measures lead to more reliable downstream uncertainty metrics such as semantic entropy.</li>
          <li>Overall, token-level temperature optimisation provides a <strong>simple, robust, and computationally efficient</strong> approach for improving the reliability of language models.</li>
        </ul>
      </div>
    </div>
  </div>
</section>





<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <div class="bibtex-header">
        <h2 class="title">BibTeX</h2>
        <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
          <i class="fas fa-copy"></i>
          <span class="copy-text">Copy</span>
        </button>
      </div>
      <pre id="bibtex-code"><code>@article{lamb2025,
  title={Improving Semantic Uncertainty Quantification in Language Models via Token-Level Temperature Scaling},
  author={Lamb, T.A. and Ivanova, Desi and Torr, Philip H.S. and Rudner, Tim G.J.},
  journal={arXiv preprint},
  year={2025},
  archivePrefix={arXiv},
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
